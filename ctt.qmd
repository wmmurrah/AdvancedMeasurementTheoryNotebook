---
title: Classic Test Theory 
format:  
  html:
    code-copy: true
---

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
opts_chunk$set(echo = TRUE, comment = NULL)
library(psych)
library(MPsychoR)
```


## Measurement in Science

**Measurement** is the quantification of theoretical constructs by means of assigning labels or numbers to observation, in a systematic way.
This is one way in which we simplify reality as a means to better understand it.
The vast majority, maybe all, of the constructs we want to learn about are not directly measurable.
When we make measurement, we inevitably must leave out some information about what we are observing, hence simplifying it.

A very important issue in measurement is validity. 
**Validity** generally is the extent to which our measures reflect what we are attempting to measure, in a particular context.
A similar concept is **reliability**, which deals with the consistency of our measures in a given context.
If we were to take the same measurement of the same thing in the same context, we would expect to get the same measurement. 
To the extent that this is true, the measure is reliable.
Note that to be valid an instrument must be reliable, but just because an instrument is reliable does not mean it is valid.

The concept of **invariance** relates to the extent to which scores on a measure are independent of examinee characteristics not relevant to the construct attempting to be measured. 
These characteristics can include things like gender, ethnicity, cultural background etc.

### Scales of Measurement

They way we quantify or classify constructs to generate measures can be classified by the scheme in the following figure.

```{mermaid}
flowchart TB
  A[Scales of Measurement] --> B[Qualitative/Categorical]
  A --> C[Quantitative/Numeric]
  B --> D[Nominal]
  B --> E[Ordinal]
  C --> F[Interval]
  C --> G[Ratio]
```


To understand the scales of measurement, let's use a data example.
First, we will import a small data set of questions I ask students in some of my statistics classes.

```{r}
#| eval: false
# File location on github:
file_location <- "https://raw.githubusercontent.com/wmmurrah/AdvancedMeasurementTheoryNotebook/main/data/student_survey.csv"

# Import data from csv file:
student_survey <- read.csv(file = file_location,
                           header = TRUE)
# View raw data
student_survey
```

```{r}
#| echo: false
file_location <- "https://raw.githubusercontent.com/wmmurrah/AdvancedMeasurementTheoryNotebook/main/data/student_survey.csv"
# Import data from csv file:
student_survey <- read.csv(file = file_location,
                           header = TRUE)

rmarkdown::paged_table(student_survey, options = list(cols.print = 5))
```

You can look at the codebook for this data below in section 3.5.1.
We can see that all of the variables are coded as integers (see the `<int>` under the variable name in the data frame), with the exception of gender with is a character string (`<chr>`). 
But if you look over the variables, and read the variable descriptions in the codebook,  you may realize that some of the variables are not best considered numeric.
We will need to recode those variables.
While we do that we will discuss scales of measurement.

For example, we can see that the `sem` variable quantifies the current semester (Spring, Fall, or Summer) for the student taking the survey.
Here we table this variable
```{r}
table(student_survey$sem)
```

Semester is clearly either a nominal or ordinal scale of measurement.
It could be ordinal because, in a given calendar year spring comes before summer which comes before fall.
But for our purposes of this survey the ordering is not important, so we will ignore it for now and create a nominal variable.
In R we do this with the `factor()` function as follows:

```{r}
student_survey$sem <- factor(student_survey$sem,
                             levels = c(1:3),
                             labels = c("Spring", "Fall", "Summer"))
```

This code tells R to create an object in side of `student_survey` called `sem`.
Because this object already exists here, this code will replace the existing object with the new one.
Then the `factor()` function take an object as the first argument (`student_survey$sem`) which is the old object.
So, essentially we are going take the old object turn it into a factor and replace the old object with the newly created factor.
The next argument  `levels = c(1:3)` tells R that the values of the original object are the integers 1, 2, and 3. 
Then, the `labels = c("Spring", "Fall", "Summer")` argument maps the three character strings ("Spring", "Fall", "Summer") onto the integers 1, 2, and 3. 
The ordering of the two vectors (1, 2, and 3 on the one hand and "Spring", "Fall", "Summer" on the other are important.
"Spring" is mapped onto 1, "Fall" onto 2, and "Summer" onto 3.
After doing this we can table this variable again and see what happened.

```{r}
table(student_survey$sem)
```

We can do something similar with the `hand` variable, which the codebook states captures the student's handedness, and also is a nominal variable.
But this time instead of saving the new variable over the old, I will create a new variable I will call `handedness`.

```{r}
student_survey$handedness <- factor(student_survey$hand, 
                                    levels = c(1,2),
                                    labels = c("left", "right"))
```

The major difference here is on the left side of the assignment operator (`<-`).
Instead of using the same name of the original object `hand`, I gave it a new name `handedness`.
Also note that in the `levels` argument, instead of the `1:2` shortcut I used `c(1,2)`, does the same thing.

```{r}
table(student_survey$handedness)
```

We have two more nominal variables gender and course.
Next, let's recode `gender`.
Because this variable contains character strings, which we can use as the labels, the code is simpler, we do not have to pass the `levels` or `labels` arguments.

```{r}
student_survey$gender <- factor(student_survey$gender)
```

```{r}
table(student_survey$gender)
```

Our final nominal variable is  `course`, which measures which course the student taking the survey was enrolled.
Because the labels are a bit more cumbersome, and to keep the code readable, we will first create a vector of the labels called `lbls`.
Then we can use that vector in the `factor()` function.
When we are done with the `lbls` object we will remove it with the `rm()` function.
Finally, we will table the new variable.

```{r}
# Create temporary labels for course factor.
lbls <- c("ERMA 7200 Basic Methods in Education Research",
          "ERMA 7300 Design and Analysis I",
          "ERMA 7310 Design and Analysis II",
          "ERMA 8340 Advanced Psychometrics")
student_survey$course <- factor(student_survey$course, 
                                levels = c(1,2,3,4),
                                labels = lbls)
rm(lbls) # Remove labels object

table(student_survey$course)
```

Ordinal Variables are those that have a natural order but the interval between those variables is not necessary the same across the different values.
It the student survey data an example is `birth` which measured the birth order of students.

```{r}
student_survey$birth <- ordered(student_survey$birth)

table(student_survey$birth)
```

The last 20 variables of the student survey are question that ask about research and statistics.
These are also measured as integers but should be ordinal variables. 
Creating a vector of labels as we did with the `course` variable, is also useful when you need to recode several variables with the same labels, such as in a set of variables that use the same Likert scale, as is the case for the Research and Statistics questions in the student survey.
Below, we again create a object called `lbls` with the Likert labels.
Then we create a vector of the column numbers that contain the Likert items, which are the 15th through the 31st columns, and name it `cols`.
In R the square brackets are indexing functions and it allows us to use only a subset of the columns in the data frame.
Then we use the `lapply` to repeat the `factor()` function for each of the Likert columns.

```{r}
# Likert labels
lbls <- c("strongly disagree", "disagree", "neither agree/disagree", 
          "agree", "strongly agree")

# Column numbers containing Likert variables.
cols <- 12:31

# Use indexing to transform all Likert items to ordered factor.
student_survey[ ,cols] <- lapply(student_survey[ ,cols], 
                               function(x) factor(x, 
                                                  levels = c(1,2,3,4,5),
                                                  labels = lbls, 
                                                  ordered = TRUE))

```

Note that to make a function ordered, which is the way to create ordinal variables in R, you pass the value `TRUE` to the `ordered` function. 
It will use the order of `levels` to order the values.


Here is the new dataframe

```{r}
#| eval: false
student_survey
```

```{r}
#| echo: false
rmarkdown::paged_table(student_survey, options = list(cols.print = 5))
```
## Classical True Score Model

The true score model is:
$$
X = T + E \tag{1}
$$
where $X$ is the **observed score**, $T$ is the **true score**, which is unknown, and $E$ is the **error**

Four assumptions to the model above:

1. $E(X) = T$, the expected value of the observed score $X$ is the true score $T$.

2. $Cov(T,E) = 0$, the true score ane error are independent(not correlated)

3. $Cov(E_1, E)2 = 0$, errors across test forms are independent.

4. $Cov(E_1, T_2) = 0$, error on one form of test is independent of the true score on another form.

Which leads to a re-expression of equation (1) above:

$$
\sigma^2_X = \sigma^2_T + \sigma^2_E
$$

To demonstrate this let's assume we have the following data [^1] , which was generated to meet these assumptions.

```{r}
# Filepath to data on github. 
filepath <- "https://raw.githubusercontent.com/wmmurrah/AdvancedMeasurementTheoryNotebook/main/code/generateToy_CTTdata.R"
source(filepath)
CTTdata
```

where `id` is a variable indicating individual test-takers, `time` indicated which of 3 times each individual was assessed, `x1` - `x10` are the scores on 10 items that comprise the test, and `Tau` is the true value of the individuals ability. 
I use `Tau` here instead of `T`, because `T` is a protected symbol in R which is short-hand for `TRUE`.
Note that we would not know `Tau` in most situations, but because this is simulated data we will pretend we do.

We can create a composite score for the ten items for each individual on each occasion by averaging columns 3 through 12.

```{r}
CTTdata$X <- rowMeans(CTTdata[ ,3:12])
```

And we can also create `E`, the error with:

```{r}
CTTdata$E <- CTTdata$X - CTTdata$Tau
```
Again, in practice we would not be able to directly compute `E` because we would not know `Tau`, but we will use it to build an understanding of what error is.

Now we have:

```{r}
CTTdata
```
Look over the last three columns and make sure you understand their relation. 
For example, in the first row, note that `X` is .2 points above `Tau`, which is exactly the value of `E` we computed ($X_1 - T_1 = E_1 =  4.2 - 4 = .2$).
The 1 subscript in the previous expression indicated row 1 (i.e. i = 1).


```{r}
CTTdata$X_t <- round(ave(CTTdata$X, CTTdata$id, FUN = mean),1)
```

```{r}
CTTdata
```

## Reliability

$$
\text{reliability} = \frac{\sigma^2_T}{\sigma^2_X} = \frac{\sigma^2_T}{\sigma^2_T + \sigma^2_E} = \rho^2_{XT}
$$

The reliability is the proportion of variance of $T$ in $X$, which is also the squared correlation between $X$ and $T$.

```{r}
Tau <- CTTdata$Tau
X <- CTTdata$X
E <- CTTdata$X - CTTdata$Tau
```

```{r}
var(Tau)/var(X)
```
```{r}
var(Tau)/(var(Tau) + var(E))
```

```{r}
cor(Tau, X)^2
```

```{r}
#| warning: false
#| message: false
library(hemp)
split_half(CTTdata, type = "alternate")
```
```{r}
coef_alpha(CTTdata)
```


```{r}
plot(x = CTTdata$Tau, y = CTTdata$id, xlim = c(1,10),
     ylim = c(0,7))
points(x = CTTdata$X, y = jitter(CTTdata$id), pch = 3, col = "red")
points(x = ave(x = CTTdata$X, factor(CTTdata$id), FUN = mean), y = CTTdata$id, 
       col = "blue", pch = 18)

 points(x = CTTdata$X_t, pch = 2, factor(CTTdata$id))
```

### Cronbach's $\alpha$

In the notes for this chapter, I demonstrate aspects of classical test theory, reliability and generalizability theory using data from a study exploring the motivation of R package authors [@mair2015motivation]. 
This tutorial is based on Chapter 1 of @mair2018modern, which can be consulted for a more in depth exposition of the underlying theory.
Here I focus on demonstrating some of those concepts in R, as well as describing how to get certain results in R.

First, I load the packages used in this tutorial:

```{r}
# Packages used:
library(psych)
library(MPsychoR)
```


Next, I load the full data set from the `MPsychoR` package [@Mair2020mpsychor], then as in the chapter, I subset the data to only include hybrid motivation items, followed by removing rows with missing values.

```{r, echo=TRUE}
data("Rmotivation")

# Create data frame with only Hybrid Motivation items.
HybMot <- subset(Rmotivation, 
                        select = grep("hyb", names(Rmotivation)))
# Remove rows  with any missing data.
HybMot <- na.omit(HybMot)

```

This leads to a data set with 777 authors and 19 items.

```{r}
# How many authors(rows) and items(columns)?
dim(HybMot)
# Note they are all dichotomous items.
head(HybMot)
```


```{r}
# Variance/Covariance Matrix
vcmat <- cov(HybMot)
scroll_box(kable(vcmat, digits = 2), width = "100%")
```


```{r}
k <- ncol(HybMot)
sigma2_Xi <- tr(vcmat) # trace of matrix or sum(diag(vmat))
sigma2_X <- sum(vcmat)
```
### Other Reliability Coefficients

## R Scripts and Data
### Student Survey Data Codebook

```{r}
#| echo: false
writeLines(readLines("data/student_survey_codebook.txt"))
```

### Simulating CTT data

```{r}
#------------------------------------------------------------------------
# Title: simulate_CTTdata
# Author: William Murrah
# Description: Simulate data to demonstrate CTT and reliability
# Created: Monday, 09 August 2021
# R version: R version 4.1.0 (2021-05-18)
# Project(working) directory: /Users/wmm0017/Projects/Courses/
#   AdvancedMeasurementTheoryNotebook
#------------------------------------------------------------------------

simx <- function(truescore, sigmax = 1) {
  x <- rnorm(18, truescore, sigmax)
  return(round(x))
}
id <- rep(1:6, each = 3)
Tau <- rep(rep(4:6, each = 3),2)
set.seed(20210805)
CTTdata <- data.frame(
  id = id,
  time = rep(1:3, 6),
  x1 = simx(Tau),
  x2 = simx(Tau),
  x3 = simx(Tau),
  x4 = simx(Tau),
  x5 = simx(Tau),
  x6 = simx(Tau),
  x7 = simx(Tau),
  x8 = simx(Tau),
  x9 = simx(Tau),
  x10 = simx(Tau),
  Tau = Tau
)
rm(id, Tau, simx)

```

[^1]: You can use the code below or copy the R script is at end of this chapter and store it on your computer, though you will have to adapt the code to your location
