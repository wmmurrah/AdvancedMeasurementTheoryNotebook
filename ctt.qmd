# Classic Test Theory {#CCT}

```{r setup, include=FALSE}
library(knitr)
library(kableExtra)
opts_chunk$set(echo = TRUE, comment = NULL)
library(psych)
library(MPsychoR)
```


## Overview

Three important concepts:

1. We can build a model of instruments similar to the way we model conceptual relationships (measurement model vs. structural model).
2. The concept of reliability
3. Measurement models can account for different sources of error.

## Classical True Score Model

The true score model is:
$$
X = T + E
$$
where $X$ is the **observed score**, $T$ is the **true score**, which is unknown, and $E$ is the **error**

To demonstrate this let's assume we have the following data (R script is at end of this chapter),

```{r}
source("code/simulate_CTTdata.R")
CTTdata
```

where `id` is a variable indicating individual test-takers, `time` indicated which of 3 times each individual was assessed, `x1` - `x10` are the scores on 10 items that comprise the test, and `Tau` is the true value of the individuals ability. 
I use `Tau` here instead of `T`, because `T` is a protected symbol in R which is short-hand for `TRUE`.
Note that we would not know `Tau` in most situations, but because this is simulated data we will pretend we do.

We can create a composite score for the ten items for each individual on each occasion by averaging columns 3 through 12.

```{r}
CTTdata$X <- rowMeans(CTTdata[ ,3:12])
```

And we can also create `E`, the error with:

```{r}
CTTdata$E <- CTTdata$X - CTTdata$Tau
```
Again, in practice we would not be able to directly compute `E` because we would not know `Tau`, but we will use it to build an understanding of what error is.

Now we have:

```{r}
CTTdata
```
Look over the last three columns and make sure you understand their relation. 
For example, in the first row, note that `X` is .2 points above `Tau`, which is exactly the value of `E` we computed ($X_1 - T_1 = E_1 =  4.2 - 4 = .2$).
The 1 subscript in the previous expression indicated row 1 (i.e. i = 1).


```{r}
CTTdata$X_t <- round(ave(CTTdata$X, CTTdata$id, FUN = mean),1)
```

```{r}
CTTdata
```

## Reliability

$$
\text{reliability} = \frac{\sigma^2_T}{\sigma^2_X} = \frac{\sigma^2_T}{\sigma^2_T + \sigma^2_E} = \rho^2_{XT}
$$

The reliability is the proportion of variance of $T$ in $X$, which is also the squared correlation between $X$ and $T$.

```{r}
Tau <- CTTdata$Tau
X <- CTTdata$X
E <- CTTdata$X - CTTdata$Tau
```

```{r}
var(Tau)/var(X)
```
```{r}
var(Tau)/(var(Tau) + var(E))
```

```{r}
cor(Tau, X)^2
```


```{r}
plot(x = CTTdata$Tau, y = CTTdata$id, xlim = c(1,10),
     ylim = c(0,7))
points(x = CTTdata$X, y = jitter(CTTdata$id), pch = 3, col = "red")
points(x = ave(x = CTTdata$X, factor(CTTdata$id), FUN = mean), y = CTTdata$id, 
       col = "blue", pch = 18)
# points(x = CTTdata$X_t, pch = 2, factor(CTTdata$id))
```

### Cronbach's $\alpha$

In the notes for this chapter, I demonstrate aspects of classical test theory, reliability and generalizability theory using data from a study exploring the motivation of R package authors [@mair2015motivation]. 
This tutorial is based on Chapter 1 of @mair2018modern, which can be consulted for a more in depth exposition of the underlying theory.
Here I focus on demonstrating some of those concepts in R, as well as describing how to get certain results in R.

First, I load the packages used in this tutorial:

```{r class.source="bluecode"}
# Packages used:
library(psych)
library(MPsychoR)
```


Next, I load the full data set from the `MPsychoR` package [@Mair2020mpsychor], then as in the chapter, I subset the data to only include hybrid motivation items, followed by removing rows with missing values.

```{r, echo=TRUE}
data("Rmotivation")

# Create data frame with only Hybrid Motivation items.
HybMot <- subset(Rmotivation, 
                        select = grep("hyb", names(Rmotivation)))
# Remove rows  with any missing data.
HybMot <- na.omit(HybMot)

```

This leads to a data set with 777 authors and 19 items.

```{r style="background: blue;"}
# How many authors(rows) and items(columns)?
dim(HybMot)
# Note they are all dichotomous items.
head(HybMot)
```


```{r}
# Variance/Covariance Matrix
vcmat <- cov(HybMot)
scroll_box(kable(vcmat, digits = 2), width = "100%")
```


```{r}
k <- ncol(HybMot)
sigma2_Xi <- tr(vcmat) # trace of matrix or sum(diag(vmat))
sigma2_X <- sum(vcmat)
```
### Other Reliability Coefficients


## Generalizability Theory

Generalizability theory, or G-theory for short, is an extension of CTT, which decomposes the one error term in CTT into multiple sources of error called *facets*. 
These could include sources such as items, raters, or measurement occasions.
These were each given a subscript on page 2 of the text.

Before looking at these different sources of error, let's calculate Cronbach's $\alpha$ in a different way, that will allow this decomposition going forward.

We will first need to reshape the data from wide to long format. 
A great tutorial on reshaping data with the `reshape2` package can be found here:

https://seananderson.ca/2013/10/19/reshape/

Basically, we need to transform the data so that instead of each item being in a separate column are reshaped so there is one column with the cell values, and one column that identifies which item the score is from.

```{r}
library("reshape2")
# Add person variable
Hyb1 <- data.frame(HybMot, person = 1:nrow(HybMot))
Hyblong <- melt(Hyb1, id.vars = c("person"), variable.name = "item")
Hyblong$person <- as.factor(Hyblong$person)
```


### Reliability and Generalizability


```{r}
summary(aov(value ~ person + item, data = Hyblong))
```

From this output we can calculate Cronbach's $\alpha$ with the following values:

```{r}
MSp <- 0.85
MSe <- 0.15

alpha <- (MSp - MSe)/MSp
print(alpha, digits = 2)
```

```{r}
ICC(HybMot)
```


```{r}
icchyb <- ICC(HybMot)
sqrt((0.85-0.15)/19)
sqrt((31.88-0.15)/777)

library("lme4")
VarCorr(lmer(value ~ (1|person) + (1|item), data = Hyblong))

library("gtheory")
gfit <- gstudy(data = Hyblong, formula = value ~ (1|person) + (1|item))
dfit <- dstudy(gfit, colname.objects = "person", colname.scores = "value", 
               data = Hyblong)
round(dfit$generalizability, 3)
```

### Multiple Sources of Error

Generalizability theory acknowledges that multiple sources of error can impact scores simultaneously, and allow for estimating the effects of each [@raykov2011introduction].
These various sources of error, or facets (e.g., items, raters, measurement occasions).
All measurements of behavior are conceptualized as being sampled from a *universe* of admissible observations [@raykov2011introduction].
If the observed score is expected to vary across a facet (e.g. vary across occasions, or vary depending on the items included, or the rater scoring), then that facet is a defining characteristic of the universe.
The idea of reliability is replace with the idea of generalizability, which ,instead of asking how accurately observed scores can reflect the true score (CTT), generalizability theory asks how accurately observed scores allow us to generalize about behavior of an individual in a particular universe.

Below is the code from the @mair2018modern text.
```{r}
library(gtheory)

data("Lakes")
phydat <- subset(Lakes, subtest == "physical")
phydat$item <- droplevels(phydat$item)
head(phydat)

formula <- score ~ (1|personID) + (1|raterID) + (1|item) + 
  (1|personID:raterID) + (1|personID:item) + (1|raterID:item)
gfit <- gstudy(formula = formula, data = phydat)
gfit
```

```{r}
dfit <- dstudy(gfit, colname.objects = "personID", colname.scores = "score", 
               data = phydat)
dfit$components
```

```{r}
dfit$var.error.abs
dfit$sem.abs
dfit$var.error.rel
dfit$sem.rel
dfit$dependability
dfit$generalizability
```

## Additional Readings

For more information of G theory, see @raykov2011introduction. 
For an example using the R package `lavaan` with G theory, see @Jorgensen2021Howestimateabsolute.

## R Scripts

### Simulating CTT data

```{r}
#------------------------------------------------------------------------
# Title: simulate_CTTdata
# Author: William Murrah
# Description: Simulate data to demonstrate CTT and reliability
# Created: Monday, 09 August 2021
# R version: R version 4.1.0 (2021-05-18)
# Project(working) directory: /Users/wmm0017/Projects/Courses/AdvancedMeasurementTheoryNotebook
#------------------------------------------------------------------------

simx <- function(truescore, sigmax = 1) {
  x <- rnorm(18, truescore, sigmax)
  return(round(x))
}
id <- rep(1:6, each = 3)
Tau <- rep(rep(4:6, each = 3),2)
set.seed(20210805)
CTTdata <- data.frame(
  id = id,
  time = rep(1:3, 6),
  x1 = simx(Tau),
  x2 = simx(Tau),
  x3 = simx(Tau),
  x4 = simx(Tau),
  x5 = simx(Tau),
  x6 = simx(Tau),
  x7 = simx(Tau),
  x8 = simx(Tau),
  x9 = simx(Tau),
  x10 = simx(Tau),
  Tau = Tau
)
rm(id, Tau, simx)

```

